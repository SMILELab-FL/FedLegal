data_config:
  dataset_name: legal

federated_config:
  rounds: 20
  sample: 1.0
  partition_method: silo
  clients_num: 10
  pson: true # local test
  pson_round_len: 1  # local client eval per 10 roundï¼Œ
  pson_log_test_len: 1  # local client test per 10 round
  test_rounds: true  # global server test
  log_test_len: 1  # global server test freq. And default 10 global test freq
  eval_rounds: true  # global server eval
  log_eval_len: 1  # global server eval freq. And default 1 global eval freq
  prox_mu: 0.005


model_config:
  model_type: roberta-wwm-ext
  model_output_mode: token_classification_crf
  permutation_layers: true
  client_model_layers: [0,1,2,3,4,5]
  server_model_layers: [0,1,2,3,4,5]
  tuning_type:
#  tuning_type: adapter_roberta-base
#  tuning_type: soft_prompt_roberta-base
#  tuning_type: lora_roberta-base
#  tuning_type: bitfit_roberta-base
#  tuning_type: prefix_roberta-base

training_config:
  per_device_train_batch_size: 16
#  per_device_train_batch_size: 8
  num_train_epochs: 1
  learning_rate: 5e-5
  metric_name: legal
  seed: 42
  do_predict: true  # client predict finally
  model_save: false

